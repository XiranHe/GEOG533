ratio <- as.numeric(sup_ratio)
hist(ratio)
Tweets <- list()
Tweets.text <- list()
analysis <- list()
sup_ratio <- list()
weight_ratio <- list()
for(i in 1:15){
Tweets[[i]] <- searchTwitter('Trump',n = 500,locale = 11/i/17)
Tweets.text[[i]] = laply(Tweets[[i]],function(t)t$getText()) # gets text from Tweets
analysis[[i]] = score.sentiment(Tweets.text[[i]], pos, neg) # calls sentiment function
k <- 0
cal <- analysis[[i]]$score
for(j in 1:500){
if(cal[j]>=1){
k <- k+1
}
}
sup_ratio[i] <- k/500
}
ratio <- as.numeric(sup_ratio)
hist(ratio)
table(analysis[[1]]$score)
for(i in 16:30){
Tweets[[i]] <- searchTwitter('Trump',n = 500,locale = 11/i/17)
Tweets.text[[i]] = laply(Tweets[[i]],function(t)t$getText()) # gets text from Tweets
analysis[[i]] = score.sentiment(Tweets.text[[i]], pos, neg) # calls sentiment function
k <- 0
cal <- analysis[[i]]$score
for(j in 1:500){
if(cal[j]>=1){
k <- k+1
}
}
sup_ratio[i] <- k/500
}
for(i in 1:30){
k <- 0
g <- 0
cal <- analysis[[i]]$score
for(j in 1:500){
if(cal[j]>=1){
k <- k+cal[j]
}
if(cal[j]<0){
g <- g+abs(cal[j])
}
}
weight_ratio[i] <- k/(k+g)
}
table(analysis[[1]]$score)
weight_ratio <- as.numeric(weight_ratio)
hist(weight_ratio)
for(i in 16:30){
Tweets[[i]] <- searchTwitter('Trump',n = 500,locale = 11/i/17)
Tweets.text[[i]] = laply(Tweets[[i]],function(t)t$getText()) # gets text from Tweets
analysis[[i]] = score.sentiment(Tweets.text[[i]], pos, neg) # calls sentiment function
k <- 0
cal <- analysis[[i]]$score
for(j in 1:500){
if(cal[j]>=1){
k <- k+1
}
}
sup_ratio[i] <- k/500
}
for(i in 1:30){
k <- 0
g <- 0
cal <- analysis[[i]]$score
for(j in 1:500){
if(cal[j]>=1){
k <- k+cal[j]
}
if(cal[j]<0){
g <- g+abs(cal[j])
}
}
weight_ratio[i] <- k/(k+g)
}
weight_ratio <- as.numeric(weight_ratio)
hist(weight_ratio)
knitr::opts_chunk$set(echo = TRUE)
```
if (!require(twitteR)) {install.packages("twitteR")}
if (!require(ROAuth)) {install.packages("ROAuth")}
library(twitteR)
library(ROAuth)
# you must get the following information from the Twitter App you just created
my.consumer.key = "jGMlhMS8kBFdXd8eYZElRbzJH"
my.consumer.secret = "HMTxTdQ1IruiQT4PkeK0upLxKpsBBcql2gDIkUUOXfoIG0KYFl"
my.access.token = "917361228456095745-uJSuEQNSwGhrYhhycgX9i3UHRo73DnH"
my.access.token.secret = "RQFqWp5xI0gv1uzi41MfH5F2UWjLw3hhdVljrQOO4hxmP"
my_oauth <- setup_twitter_oauth(consumer_key = my.consumer.key, consumer_secret = my.consumer.secret, access_token = my.access.token, access_secret = my.access.token.secret)
tweets <- searchTwitter("#Trump", n=1000, lang="en")
tweets.text <- sapply(tweets, function(x) x$getText())
# Replace blank space (ârtâ)
tweets.text <- gsub("rt", "", tweets.text)
# Replace @UserName
tweets.text <- gsub("@\\w+", "", tweets.text)
# Remove punctuation
tweets.text <- gsub("[[:punct:]]", "", tweets.text)
# Remove links
tweets.text <- gsub("http\\w+", "", tweets.text)
# Remove tabs
tweets.text <- gsub("[ |\t]{2,}", "", tweets.text)
# Remove blank spaces at the beginning
tweets.text <- gsub("^ ", "", tweets.text)
# Remove blank spaces at the end
tweets.text <- gsub(" $", "", tweets.text)
# #convert all text to lower case
tweets.text <- tolower(tweets.text)
if(!require(tm)) {install.packages("tm")}
library(tm)
#create corpus
tweets.text.corpus <- Corpus(VectorSource(tweets.text))
#clean up by removing stop words
tweets.text.corpus <- tm_map(tweets.text.corpus, function(x) removeWords(x,stopwords()))
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(tweets.text.corpus,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 150)
setwd("C:/Users/Lei/Documents/First year of graduate/Statistics for Geography/Final project/Final project"）
neg = scan("negative-words.txt", what="character", comment.char=";")
pos = scan("positive-words.txt", what="character", comment.char=";")
score.sentiment = function(tweets, pos.words, neg.words)
{
scores = laply(tweets, function(tweet, pos.words, neg.words) {
tweet = gsub('https://','',tweet) # removes https://
tweet = gsub('http://','',tweet) # removes http://
tweet=gsub('[^[:graph:]]', ' ',tweet) ## removes graphic characters  #like emoticons
tweet = gsub('[[:punct:]]', '', tweet) # removes punctuation
tweet = gsub('[[:cntrl:]]', '', tweet) # removes control characters
tweet = gsub('\\d+', '', tweet) # removes numbers
tweet=str_replace_all(tweet,"[^[:graph:]]", " ")
tweet = tolower(tweet) # makes all letters lowercase
word.list = str_split(tweet, '\\s+') # splits the tweets by word in a list
words = unlist(word.list) # turns the list into vector
pos.matches = match(words, pos.words) ## returns matching values for words from list
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches) ## converts matching values to true of false
neg.matches = !is.na(neg.matches)
score = sum(pos.matches) - sum(neg.matches) # true and false are treated as 1 and 0 so they can be added
return(score)
}, pos.words, neg.words )
scores.df = data.frame(score=scores, text=tweets)
return(scores.df)
}
tweets = searchTwitter('Trump',n=500)
Tweets.text = laply(tweets,function(t)t$getText()) # gets text from Tweets
analysis = score.sentiment(Tweets.text, pos, neg) # calls sentiment function
Tweets <- list()
Tweets.text <- list()
analysis <- list()
sup_ratio <- list()
weight_ratio <- list()
for(i in 1:15){
Tweets[[i]] <- searchTwitter('Trump',n = 500,locale = 11/i/17)
Tweets.text[[i]] = laply(Tweets[[i]],function(t)t$getText()) # gets text from Tweets
analysis[[i]] = score.sentiment(Tweets.text[[i]], pos, neg) # calls sentiment function
k <- 0
cal <- analysis[[i]]$score
for(j in 1:500){
if(cal[j]>=1){
k <- k+1
}
}
sup_ratio[i] <- k/500
}
ratio <- as.numeric(sup_ratio)
hist(ratio)
for(i in 16:30){
Tweets[[i]] <- searchTwitter('Trump',n = 500,locale = 11/i/17)
Tweets.text[[i]] = laply(Tweets[[i]],function(t)t$getText()) # gets text from Tweets
analysis[[i]] = score.sentiment(Tweets.text[[i]], pos, neg) # calls sentiment function
k <- 0
cal <- analysis[[i]]$score
for(j in 1:500){
if(cal[j]>=1){
k <- k+1
}
}
sup_ratio[i] <- k/500
}
for(i in 1:30){
k <- 0
g <- 0
cal <- analysis[[i]]$score
for(j in 1:500){
if(cal[j]>=1){
k <- k+cal[j]
}
if(cal[j]<0){
g <- g+abs(cal[j])
}
}
weight_ratio[i] <- k/(k+g)
}
weight_ratio <- as.numeric(weight_ratio)
hist(weight_ratio)
setwd("C:/Users/Lei/Documents/First year of graduate/Statistics for Geography/Final project/Final project"）
neg1 = scan("R.txt", what="character", comment.char=";")
approve <- as.numeric(neg1)
ratio <- as.numeric(sup_ratio)
x <- approve
y <- ratio
plot(y ~ x)
m <- lm(y~x)
summary(m)
abline(m,col="red",lwd=2)
segments(x,fitted(m),x,y,col="blue",lty = "dashed")
print("the relationship between approval rating of Trump and attitude of netizen is: y*attitude = 1.5318*approval rating - 0.08278")
Wratio <- as.numeric(weight_ratio)
weight_x <- approve
weight_y <- Wratio
plot(weight_y ~ weight_x)
weight_m <- lm(weight_y~weight_x)
summary(weight_m)
abline(weight_m,col="blue",lwd=2)
segments(weight_x,fitted(weight_m),weight_x,weight_y,col="blue",lty = "dashed")
print("there is no correction bewteen the approval rating of Trump and the weight ratio of netizens' attitude")
library("shiny")
library("flexdashboard")
install.packages("flexdashboard")
library("shiny")
library("flexdashboard")
library("ggplot2")
## Teaching package from: www.ncl.ac.uk/maths/rcourse/details.html
## install.packages("nclRshiny", repos="http://rcourses.github.io/drat/")
## Subset of the ggplot2movies data set
data(movies, package="nclRshiny")
library("ggplot2")
## Teaching package from: www.ncl.ac.uk/maths/rcourse/details.html
install.packages("nclRshiny", repos="http://rcourses.github.io/drat/")
## Subset of the ggplot2movies data set
data(movies, package="nclRshiny")
neg1 = scan("R.txt", what="character", comment.char=";")
approve <- as.numeric(neg1)
ratio <- as.numeric(sup_ratio)
x <- approve
y <- ratio
plot(y ~ x)
m <- lm(y~x)
summary(m)
abline(m,col="red",lwd=2)
approve <- as.numeric(neg1)
ratio <- as.numeric(sup_ratio)
x <- approve
y <- ratio
plot(y ~ x)
m <- lm(y~x)
summary(m)
abline(m,col="red",lwd=2)
segments(x,fitted(m),x,y,col="blue",lty = "dashed")
print("the relationship between approval rating of Trump and attitude of netizen is: y*attitude = 1.5318*approval rating - 0.08278")
neg1 = scan("R.txt", what="character", comment.char=";")
approve <- as.numeric(neg1)
ratio <- as.numeric(sup_ratio)
x <- approve
y <- ratio
plot(y ~ x)
m <- lm(y~x)
summary(m)
abline(m,col="red",lwd=2)
segments(x,fitted(m),x,y,col="blue",lty = "dashed")
neg1 = scan("R.txt", what="character", comment.char=";")
approve <- as.numeric(neg1)
x <- approve
y <- ratio
plot(y ~ x)
m <- lm(y~x)
abline(m,col="red",lwd=2)
segments(x,fitted(m),x,y,col="blue",lty = "dashed")
setwd("C:/Users/Lei/Documents/First year of graduate/Statistics for Geography/Final project/Final project"）
neg1 = scan("R.txt", what="character", comment.char=";")
approve <- as.numeric(neg1)
ratio <- as.numeric(sup_ratio)
x <- approve
y <- ratio
plot(y ~ x)
m <- lm(y~x)
summary(m)
abline(m,col="red",lwd=2)
segments(x,fitted(m),x,y,col="blue",lty = "dashed")
print("the relationship between approval rating of Trump and attitude of netizen is: y*attitude = 1.5318*approval rating - 0.08278")
Wratio <- as.numeric(weight_ratio)
weight_x <- approve
weight_y <- Wratio
plot(weight_y ~ weight_x)
weight_m <- lm(weight_y~weight_x)
summary(weight_m)
abline(weight_m,col="blue",lwd=2)
segments(weight_x,fitted(weight_m),weight_x,weight_y,col="blue",lty = "dashed")
print("there is no correction bewteen the approval rating of Trump and the weight ratio of netizens' attitude")
Wratio <- as.numeric(weight_ratio)
```{r}
print("the relationship between approval rating of Trump and attitude of netizen is: y*attitude = 1.09922*approval rating + 0.13515")
Wratio <- as.numeric(weight_ratio)
weight_x <- approve
weight_y <- Wratio
plot(weight_y ~ weight_x)
weight_m <- lm(weight_y~weight_x)
summary(weight_m)
abline(weight_m,col="blue",lwd=2)
segments(weight_x,fitted(weight_m),weight_x,weight_y,col="blue",lty = "dashed")
print("there is no correction bewteen the approval rating of Trump and the weight ratio of netizens' attitude")
print("the relationship between approval rating of Trump and attitude of netizen is:
y*attitude = 1.09922*approval rating + 0.13515")
print("the relationship between approval rating of Trump and attitude of netizen is:y*attitude = 1.09922*approval rating + 0.13515")
print("the relationship between approval rating of Trump and weight positive attitude is:y*weight_attitude = 0.8124*approval rating + 0.46417")
df <- data.frame(ratio,weight_ratio)
m <- lm(x ~ y + weight_y, data = df)
summary(m)
anova(m)
install.packages("nclRshiny", repos="http://rcourses.github.io/drat/")
library(nclRshiny)
library("shiny", lib.loc="~/R/win-library/3.4")
library(nclRshiny)
library(shiny)
data(movies, package="shiny")
top_movies = movies[order(-movies$rating),
c("title", "year", "budget", "rating", "Romance", "Action", "Animation"), ]
library(highcharter)
install.packages("highcharter")
library("highcharter", lib.loc="~/R/win-library/3.4")
library("dplyr", lib.loc="~/R/win-library/3.4")
library("viridisLite", lib.loc="~/R/win-library/3.4")
install.packages("forecast")
library("forecast", lib.loc="~/R/win-library/3.4")
install.packages("treemap")
library("treemap", lib.loc="~/R/win-library/3.4")
library("flexdashboard", lib.loc="~/R/win-library/3.4")
library(highcharter)
library(dplyr)
library(viridisLite)
library(forecast)
library(treemap)
library(flexdashboard)
thm <-
hc_theme(
colors = c("#1a6ecc", "#434348", "#90ed7d"),
chart = list(
backgroundColor = "transparent",
style = list(fontFamily = "Source Sans Pro")
),
xAxis = list(
gridLineWidth = 1
)
)
AirPassengers %>%
forecast(level = 90) %>%
hchart() %>%
hc_add_theme(thm)
data("ratio")
data("approve")
ratio <- ratio %>%
mutate(state = rownames(.))
library(highcharter)
library(dplyr)
library(viridisLite)
library(forecast)
library(treemap)
library(flexdashboard)
thm <-
hc_theme(
colors = c("#1a6ecc", "#434348", "#90ed7d"),
chart = list(
backgroundColor = "transparent",
style = list(fontFamily = "Source Sans Pro")
),
xAxis = list(
gridLineWidth = 1
)
)
library(highcharter)
library(dplyr)
library(viridisLite)
library(forecast)
library(treemap)
library(flexdashboard)
thm <-
hc_theme(
colors = c("#1a6ecc", "#434348", "#90ed7d"),
chart = list(
backgroundColor = "transparent",
style = list(fontFamily = "Source Sans Pro")
),
xAxis = list(
gridLineWidth = 1
)
)
AirPassengers %>%
forecast(level = 90) %>%
hchart() %>%
hc_add_theme(thm)
ratio <- ratio %>%
mutate(state = rownames(.))
n <- 4
colstops <- data.frame(
q = 0:n/n,
c = substring(viridis(n + 1), 0, 7)) %>%
list.parse2()
highchart() %>%
hc_add_series_map(approve, ratio, name = "Sales",
value = "Murder", joinBy = c("woename", "state"),
dataLabels = list(enabled = TRUE,
format = '{point.properties.postalcode}')) %>%
hc_colorAxis(stops = colstops) %>%
hc_legend(valueDecimals = 0, valueSuffix = "%") %>%
hc_mapNavigation(enabled = TRUE) %>%
hc_add_theme(thm)
AirPassengers %>%
forecast(level = 90) %>%
hchart() %>%
hc_add_theme(approve)
thm
AirPassengers %>%
df <- data.frame(approve,ratio)
forecast(level = 90) %>%
hchart() %>%
hc_add_theme(df)
AirPassengers
df <- data.frame(approve,ratio)
forecast(level = 90)
hchart() %>%
hc_add_theme(df)
AirPassengers
df <- data.frame(approve,ratio)
forecast(level = 90) %>%
hchart() %>%
hc_add_theme(df)
AirPassengers
df <- data.frame(approve,ratio)
forecast(object = df,level = 90) %>%
hchart() %>%
hc_add_theme(df)
tweets <- searchTwitter("#Trump", n=1000, lang="en")
tweets.text <- sapply(tweets, function(x) x$getText())
# Replace blank space (ârtâ)
tweets.text <- gsub("rt", "", tweets.text)
# Replace @UserName
tweets.text <- gsub("@\\w+", "", tweets.text)
# Remove punctuation
tweets.text <- gsub("[[:punct:]]", "", tweets.text)
# Remove links
tweets.text <- gsub("http\\w+", "", tweets.text)
# Remove tabs
tweets.text <- gsub("[ |\t]{2,}", "", tweets.text)
# Remove blank spaces at the beginning
tweets.text <- gsub("^ ", "", tweets.text)
# Remove blank spaces at the end
tweets.text <- gsub(" $", "", tweets.text)
# #convert all text to lower case
tweets.text <- tolower(tweets.text)
if(!require(tm)) {install.packages("tm")}
library(tm)
#create corpus
tweets.text.corpus <- Corpus(VectorSource(tweets.text))
#clean up by removing stop words
tweets.text.corpus <- tm_map(tweets.text.corpus, function(x) removeWords(x,stopwords()))
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(tweets.text.corpus,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 200)
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(tweets.text.corpus,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 250)
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(tweets.text.corpus,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 150)
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(tweets.text.corpus,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 150)
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(tweets.text.corpus,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 150)
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(tweets.text.corpus,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 200)
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(tweets.text.corpus,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 200)
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(tweets.text.corpus,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 200)
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(tweets.text.corpus,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 200)
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(tweets.text.corpus,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 200)
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(tweets.text.corpus,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 200)
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(tweets.text.corpus,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 150)
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(tweets.text.corpus,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 150)
